#+hugo_base_dir: ../

#+seq_todo: TODO DRAFT DONE
#+seq_todo: TEST__TODO | TEST__DONE

#+property: header-args :eval never-export

#+startup: indent

#+macro: doc [[https://ox-hugo.scripter.co/doc/$1][$2]]
#+macro: oxhugoissue =ox-hugo= Issue #[[https://github.com/kaushalmodi/ox-hugo/issues/$1][$1]]
#+macro: hugoissue =hugo= Issue #[[https://github.com/gohugoio/hugo/issues/$1][$1]]
#+macro: hugopr =hugo= PR #[[https://github.com/gohugoio/hugo/pull/$1][$1]]
#+macro: bfissue /Blackfriday/ Issue #[[https://github.com/russross/blackfriday/issues/$1][$1]]
#+macro: commit commit [[https://github.com/kaushalmodi/ox-hugo/commit/$1][$1]]

# https://scripter.co/latex-in-html/
#+macro: latex @@html:<span class="latex">L<sup>a</sup>T<sub>e</sub>X</span>@@

#+author: Yichen Xu

* DONE First post generated by org-mode                                :test:
CLOSED: [2019-11-06 Wed 00:37]
:PROPERTIES:
:EXPORT_FILE_NAME: first-post-org-mode
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:
This is my first post generated by org-mode, ox-hugo.
* DONE Switching From Purcell's Emacs.d to Spacemacs         :tutorial:emacs:
CLOSED: [2019-11-07 Thu 10:32]
:PROPERTIES:
:EXPORT_FILE_NAME: to-spacemac
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:

很久以来，我的Emacs配置都基于无比经典的Purcell的 [[https://github.com/purcell/emacs.d][emacs.d]]。但就在最近，我突然决定切换到 Spacemacs。

我曾用过一段时间的 Spacemacs，或者，确切的说，贯穿了我高二到高三的大部分时光。但
彼时对Emacs了解颇少，对Spacemacs的使用也仅限于 uncomment 几个 layer，或是复制粘
贴几句配置到 user-config 中。大一之后，一个偶然的契机，我打算更深入地学习Emacs。
那时候开始，我一直使用并轻度定制了Purcell的Emacs配置。
[[https://github.com/Linyxus/emacs.d/commits/master][Github repo]]

但老实说，不管是配置的方法还是版本管理，我在这段时间里做的真的有些随便。

** 切换到 Spacemacs 的理由

1. Evil! Spacemacs是在emacs中使用evil的最快速的方法之一
2. 系统化的配置，基于 use-package，Purcell的配置方法过于古老不便
3. Battery included，庞大的社群： [[https://github.com/syl20bnr/spacemacs][Github]] 上已有18.8k个星星
4. 丰富的文档，相较于 Purcell 的配置基本无可用文档

** Migration

事实上，除了一些无关紧要的配置，我几乎可以无痛迁移到 Spacemacs，因为 Spacemacs 的 layer 实在是太齐全丰富了。

日常使用中，我会使用Emacs编辑的文件类型其实不是很多：
- C/C++
- Org
- Haskell
- \( \LaTeX{} \)

平时虽然Python写得也比较多，但是，PyCharm真香！

上述我要用到的编辑环境，所有在 Spacemacs 中都有现成的 layer 可以用，我要做的只是
在 =dotspacemacs-configuration-layers= 中把他们加上罢了。

** 迁移过程
首先，删除原来的emacs.d。

#+begin_src bash
rm .emacs.d // my .emacs.d is just a symlink
#+end_src

然后

#+begin_src bash
git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d
#+end_src

打开Emacs。Voila！

** 一些常用Layer与基本配置
- auto-completion，编辑器必备，看着舒服
- helm，也可以选ivy，个人觉得的确是ivy简洁好看一些，但helm是默认之选，官方文档中
  也提到如果选择ivy，一些功能也许不可用。[[https://github.com/syl20bnr/spacemacs/blob/master/doc/DOCUMENTATION.org#completion][Documentation]]
- org，不得不说，Spacemacs自带的org layer实在是太好用了！

除此以外，因为看惯了Purcell用的Tomorrow系列theme，对spacemacs自带的theme系列有些
不习惯。而且spacemacs-dark在org下实在是太难看了些，故而还是配了一下tomorrow系列
的theme，看起来很习惯。
[[file:spacemacs.png]]

只需要把tomorrow theme对应的package加到dotfile的additional-packages中即可。
#+BEGIN_SRC emacs-lisp
dotspacemacs-additional-packages '(color-theme-sanityinc-tomorrow)
#+END_SRC

别忘了选一个color theme作为默认。
#+begin_src emacs-lisp
dotspacemacs-themes '(sanityinc-tomorrow-eighties
                      spacemacs-dark
                      spacemacs-light)
#+end_src

** Version Control
Spacemacs的版本控制有很多种方式。简单来说，Spacemacs的配置文件分为以下部分
1. Spacemacs主体，也就是 =.emacs.d= 中的大部分内容。这一部分至少对我而言并不需要
   进行版本控制，因为我基本不会对其进行修改，直接跟着上游就可以了。
2. .spacemacs。也就是我基于Spacemacs的配置文件。
3. Private layers。也就是自己写的layer。

文档中有所提及的是，private layer所在的文件夹是会被Spacemacs主git repo忽略的。如
果要对我们的自用layer进行版本控制，可以简单地在private文件夹建立一个repo，或是把
一个repo symlink到private文件夹，效果类似。

但这么做有一个巨大的弊端：.spacemacs和private layer不能很好地放在一起管理。有一
个显然的解决方案：建一个管理Spacemacs配置文件的repo，里面包含一个.spacemacs文件，
一个private文件夹，再分别symlink到相应位置，但这样非常不自然。

我最终选择了另一个解决方案。[[https://github.com/syl20bnr/spacemacs/blob/master/doc/QUICK_START.org#dotdirectory-spacemacsd][文档]]中提及，除了用一个.spacemacs文件作为配置以外，
Spacemacs也可以像Emacs一样，把一个文件夹作为配置来源。具体地，新建一个文件夹
=~/.spacemacs.d= ， =~/.spacemacs.d/init.el= 即可作为原来的 =.spacemacs= 。

借助于这一特性，可以把我的Spacemacs配置和private layers集合到一个文件夹中：
#+begin_src
.spacemacs.d
├── LICENSE
├── README.org
├── init.el
└── layers
    └── ox-hugo-layer

2 directories, 3 files
#+end_src
* DONE Playing with keyboard on macOS with Karabiner         :tutorial:macos:
CLOSED: [2019-12-12 Thu 17:28]
:PROPERTIES:
:EXPORT_FILE_NAME: macos-keyboard-karabiner
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:

本文会简单地介绍 macOS 上的键盘修改工具 Karabiner，并且简单介绍我配置的修改方式。
** 引子
*** 关于 macOS 的输入法
在macOS上，一直让我很头疼的一件事情是自带的输入法对中文输入不是非常友好。由于对
中文输入者而言，在中英文之间切换是相对常见的操作，大多数人习惯使用Shift切换，因
为绝大多数中文输入法都默认这一点。但macOS上默认使用Capslock。

这并不是关键之处，让我完全不能好好使用macOS自带输入法的根本原因会在下面提到：我
需要把Capslock用作他用。

事实上，第三方输入法我也尝试过，从国产经典的搜狗，到较为小众的落格。搜狗的毛病在
于有广告，界面也未免太花里胡哨，而落格的致命之处在于词库实在太难用，有时候首选词
叫人完全无法理解，不仅如此，落格最主要的卖点：双拼，也对使用全拼的我毫无吸引力。

通过 Karabiner，可以把Shift配置为我想要的样子。
*** 关于修改CapsLock
修改CapsLock应该是很多程序员的必备操作了。Capslock的位置处于整张键盘上最容易按到
的地方之一，却基本是最少使用到的按键，这很不合理。

我们可以把Capslock转而映射到Control（对于Emacs用户）或Escape（对于Vim用户）来很
大地提高键盘的使用效率。

之前发现了一个很棒的工具，名为[[https://github.com/alols/xcape][Xcape]]，能够 *同时* 把Capslock映射到Control与Escape，
这很容易实现——Escape和Control的使用事实上是不重合的，使用场景有明显的差异：
Control是修饰键，与其他按键一起按下，而Escape常常是独立按下的。也可以通过按下的
时间来区分他们。

很遗憾的是，Xcape *并不支持macOS* 。

但 Karabiner 弥补了这一遗憾。

** Karabiner的安装

[[https://pqrs.org/osx/karabiner/][Karabiner]]

Karabiner 的安装非常简单，直接在官网上下载dmg，双击安装即可。

值得一提的是，Karabiner的官网上也有一个官方整理的 Complex modifications [[https://pqrs.org/osx/karabiner/complex_modifications/][集合]]，大
多数常用的修改方式只需要 import 这上面的修改即可，修改的定义方式是json，语法也颇
为直观，必要时可以修改。

** Modification I: 使用Shift切换中英文

利用 Shift 切换中英文有一个很直观的实现：单独按下时，发送Capslock，否则仍然发送
Shift。这个实现在上面提到的集合中就有 [[https://pqrs.org/osx/karabiner/complex_modifications/#shift][现成的]]。

然而，在使用过程中，我发现了一些问题：在一些情况下，如Chrome和PyCharm，这样的实
现会产生一些非常奇怪的Bug：输入的英文皆为大写。尝试解决无果，我转向了第二种方案：
类似实现，只不过直接发送切换输入法的快捷键，而不是Capslock。

#+begin_src javascript
  {
      "description": "Change left_shift to control+option+space if pressed alone (rev 2)",
      "manipulators": [
          {
              "from": {
                  "key_code": "left_shift",
                  "modifiers": {
                      "optional": [
                          "any"
                      ]
                  }
              },
              "to": [
                  {
                      "key_code": "left_shift"
                  }
              ],
              "to_if_alone": [
                  {
                      "hold_down_milliseconds": 100,
                      "key_code": "spacebar",
                      "modifiers": [
                          "left_control",
                          "left_option"
                      ]
                  }
              ],
              "type": "basic"
          }
      ]
  }
#+end_src

我切换输入法的快捷键是 control + option + space，这样的实现到目前为止完全符合预
期，毫无问题。

** Modification II: Capslock
Capslock的修改同样有[[https://pqrs.org/osx/karabiner/complex_modifications/#caps_lock][现成的]]。

Capslock这样的修改方式对Evil用户尤其友好——既兼顾了Evil的Escaping，又保护了Emacs
用户的小指。

这样修改过后，在Emacs中编辑基本不再需要离开键盘的中间区域了。

** Modification III: System-wide Vi-style navigation
第三个修改是针对方向键的，也即在全系统层面，用一个修饰键加上hjkl来作为方向键。

这一修改同样有 [[https://pqrs.org/osx/karabiner/complex_modifications/#vi_style_arrows][现成的]] 。

为了最大化的避免与Emacs中的快捷键发生冲突，我选用了option键。虽然按起来没有
Capslock来的方便，但至少也比方向键要快得多。
* DONE The magic of Laziness: from fibonacci to Y combinator (1) :tutorial:haskell:
CLOSED: [2020-02-12 Wed 21:17]
:PROPERTIES:
:EXPORT_FILE_NAME: the-magic-of-laziness
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:

在这篇博客中，我将简单地介绍许多函数式编程语言中一个重要的，也是独特的特性：Laziness。

** A first taste of Laziness
所以，什么是Laziness呢？Laziness有一个更加正式的名称：lazy evaluation，也即 /惰
性求值/ 。简单来说，惰性求值意味着，表达式的值不会被立即求出，只有当需要的时候才
会对其进行求值。

比如，下面的代码在运行时并不会报错，而可以安全地求出列表的长度。

#+begin_src haskell
  length [error "Hey!", error "Here is an error."]
  -- 2
#+end_src

原因是，在 =length= 的实现中，并不关心列表中每个元素的值是什么。因而他们并不会被
求值。

#+begin_src haskell
length :: [a] -> Int
length [] = 0
length (_:xs) = 1 + length xs
#+end_src

这是惰性求值这一特性最为直接的展示。

而在实现上，具有惰性求值特性的代码可以这样被直观地想象：所有的值都被装在一个盒子
中，对某个值求值的过程，也就是打开盒子的过程，为了打开这个盒子之后或许我们会发现
里面有更多的盒子要打开。而所有的盒子，都会在万不得已的时候才被打开。

这个比喻很直观，但不那么确切。比较精确的说法应当基于两个定义（至少在Haskell中是
如此）：Normal Form与Weak Head Normal Form。

Normal Form的定义很简单：normal form表示一个被完全求值的值：代表它所有的部分都已
经被完全地求值完毕。 =1= ， =Just "Hello"= ，都是normal form，而 =1 + 1= 则不是。

Weak Head Normal Formd的定义则要复杂一些。简单来说，所有函数都是WHNF。所有顶层
constructor被求值的表达式也都是WHNF。

举一些简单的例子： =(1, 2 + 2)= ， =(1 + 1) : undefined= ， =Just 0= 都是WHNF，因为
他们的顶层constructor都已求值。

而一般来说，对某个值进行求值的时候，都只会将它求值为WHNF的形式。

更为详细的介绍，可以在这一篇 [[https://alpmestan.com/posts/2013-10-02-oh-my-laziness.html][文章]] 中找到。

Laziness经常被认为会导致更多的内存占用，大多数时候的确如此：因为Laziness很多时候
会导致运算过程被保存，而不是直接求出结果。但有些时候，Laziness可以带来更高的内存
使用效率，并做到若没有Laziness则完全不可能做到的事情，举一个简单的例子。

#+begin_src haskell
  x :: [Int]
  x = 1 : x
#+end_src

上面的函数定义了一个只包含 $1$ 的无穷序列。这在非Lazy的语言中是不可能做到的：它
会消耗无穷的内存。而在Lazy的语言中，它在内存中的形态不过是一个循环链表。

** 利用惰性定义无穷序列
那么，惰性到底可以做什么有用的事情呢？

下面这段代码定义了所有自然数的序列：
#+begin_src haskell
  nat :: [Int]
  nat = 0 : map (+1) nat

  -- >>> take 3 nat
  -- [0,1,2]
#+end_src

或者，可以类似地定义等比数列 $\{ 2^n \}_{n \in \mathbb N}$：
#+begin_src haskell
xs :: [Int]
xs = 1 : map (^2) nat
#+end_src

正是惰性求值的特性，给予了我们定义无穷数列的能力。考虑下面的代码：
#+begin_src haskell
take 3 nat
-- take 3 (0 : map (+1) nat)
-- 0 : take 2 (map (+1) nat)
-- 0 : take 2 (map (+1) (0 : map (+1) nat))
-- 0 : take 2 ((0 + 1) : map (+1) (map (+1) nat))
-- 0 : (0 + 1) : take 1 (map (+1) (map (+1) nat))
-- ...
-- 0 : (0 + 1) : (0 + 1 + 1) : []
-- [0,1,2]

take :: Int -> [a] -> [a]
take n xs | n <= 0 = []
take _ [] = []
take n (x:xs) = x : take (n-1) xs
#+end_src

这段代码非常简单地解释了惰性求值的过程。值得注意的是：
- 在上面的代码中，每次对列表求值时，都仅仅求值到WHNF，也即 =x : xs= 的形式。
- =take= 中的比较 $n \le 0$ 将会强制将两端都求值到NF。

上面的定义基于了这样一个事实：所有带有符合递推式 $ a_{k+1} = f(a_k), $
且首项 $a_0$ 为 $c$ 的无穷序列，都满足这一恒等式：
#+begin_src haskell
xs === c : map f xs
#+end_src

因此我们可以对所有一阶递推序列都在Haskell中非常容易地构造出对应的无穷序列。

而对于二阶递推式也是类似的。因为我们有
#+begin_src haskell
xs === x0 : x1 : zipWith f xs (drop 1 xs)
#+end_src
其中 =f= 即为二阶递推关系式。

因而可以很容易地定义出Fibonacci数列：
#+begin_src haskell
fibo :: [Int]
fibo = 1 : 1 : zipWith (+) fibo (drop 1 fibo)
#+end_src

而类似定义的这些函数，在不具备Lazy特性的语言中是没有任何用的。调用他们只会进入死
循环。

当然，归功于Laziness，我们也能对无穷序列进行很容易的操作。例如，如果你想求出
Fibonacci数列两项之差所构成的数列（这显然也是一个Fibonacci数列），可以这样写：
#+begin_src haskell
xs = zipWith subtract fibo (drop 1 fibo)
#+end_src

=xs= 也将是一个无穷序列。

在下一篇博客中，我将介绍一个非常有趣的情景：假设我们正在使用一个非常，非常，非常
简单的纯函数语言，不仅没有任何副作用，并且简单到无法定义变量：所有名称的引入都是
通过定义匿名函数完成的。而整个程序也仅仅是一个表达式而已。我们用简单的Haskell来
模拟这种语言。也即：我们只能使用Haskell中的Lambda函数，不能定义变量。
#+begin_src haskell
(\x y -> x + y) 1 2
-- 3
#+end_src

而在这一情景下，该如何实现递归呢？也即，如果无法定义一个名称，那函数该如何“引用”
自己呢？

为了在这种情况下实现递归，我会介绍Y组合子的概念，并指出，是Laziness使Y组合子的定义成为可能。
* DONE The magic of Laziness: from fibonacci to Y combinator (2) :tutorial:haskell:
CLOSED: [2020-03-22 Sun 10:35]
:PROPERTIES:
:EXPORT_FILE_NAME: the-magic-of-laziness-2
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:
这是 The magic of Laziness 的第二篇博客。在本篇文章中，我将展示Laziness的另一个
奇妙的应用：创建递归函数。

创建递归函数自然是一件非常简单的事情，在Python中实现一个计算阶乘的函数，只需寥寥
数行：
#+begin_src python
  def fact(n: int):
      ret = 1
      for i in range(1, n+1):
          ret *= i
      return ret
#+end_src

事实上，使用函数式风格的语言来实现它，也非常容易：
#+begin_src haskell
fact n | n <= 0 = 1 | otherwise = n * fact (n-1)
#+end_src

然而，今天我想解决的问题是，如何在一个定义极度简单，甚至无法为自定义的函数绑定
“名称”的条件下，实现递归？

确切来说，我们定义这样的一种简单的玩具语言，其中只有这样的几种简单的元素：
- 自然数字面值：$0, 1, 2, \cdots$
- 变量：$x, y, z, a, b, c, \cdots$
- 必要的自然数算符：$x + y, x * 2, 2^{10}, \cdots$
- 函数表达式：$\lambda x. x+1$
- 应用函数表达式 (apply function)：$(\lambda x. x+1) 0$ (结果为$1$)，可以理解为
  函数的“计算”，等价于将函数参数在函数体中所有的出现替换为对应的值产生的表达式。

更加正确地来说，该语言的文法可以如下定义：
#+begin_src
nat ::= (0..9)+
var ::= (a..z) (a..z | 0..9)*
op ::= + | * | ^

bin_expr ::= expr op expr
lam_expr ::= \ var . expr
app_expr ::= expr expr
expr ::= bin_expr | lam_expr | app_expr | (expr) | nat | var
#+end_src

事实上，这样一种语言其实只是定义了一种书写 /表达式/ 的方式。而基于本语言的计算，
事实上也只是对表达式的化简过程。

那么，回到最初的问题，如何在这样的一个语言中实现递归呢？所谓递归，就是在函数中调
用自身，然而这个语言中根本就没有办法给函数定义一个“名字”，更不用说调用自己了。

在正式解决解决这个问题之前，需要先做一些准备工作。首先，注意到该语言定义的函数只
能接受一个参数：$\lambda x. x+1$。然而，这事实上并不会带来任何的限制，为了定义一
个接受两个参数的函数，可以这么写：$\lambda x. (\lambda y. x + y)$。也即，为了得
到一个能够接受两个参数的函数，定义一个函数：它接受一个参数，并返回另一个函数：
$\lambda y. x + y$，这一函数也能接受一个参数。那么，$\lambda x. \lambda y. x +
y$便是一个接受两个参数的函数了。

为了简化这一过程，我们可以定义一个语法糖：$\lambda x. \lambda y. x + y \equiv
\lambda xy. x + y$。

除此以外，为了给这一简单的语言一个不停留于纸面上的实现，我们可以借助Haskell，使
用Haskell的Lambda函数来进行模拟：
#+begin_src haskell
(\ x y -> x + y) 1 2
-- => 3
#+end_src

除此以外，由于不能为表达式或值绑定一个符号（也即定义他们的名称），书写有很大的麻
烦。同一个表达式，出现多少次就需要完整地书写多少遍。为了缓解这一问题，我们可以增
加类似于C macro的预处理过程：$plus := \lambda xy. x + y; plus 1 2$。注意到这不同
于普通的变量名、函数名定义，虽然形式上非常相似，但这本质上只是与C macro毫无区别
的“替换”。也即，我们无法借助它来达成定义递归函数的目的。举一个直观的例子： $fact
:= \lambda x. x * fact (x-1); fact 10$。

本质上，这只会在 /预处理/ 阶段进行 /替换/ ，且只进行一次。
如上面的表达式可以被替换成：$(\lambda x. x * fact (x - 1)) 10$。然而计算在这里就
无法继续下去了：现在我们并不知道 =fact= 应该是什么。

对应到Haskell的表示中，我们可以利用Haskell的绑定机制，对一些表达式进行绑定。但为
了让事情保持有趣，我们要信守承诺：不要在任何绑定的表达式中引用自身。

#+begin_src haskell
fact = \ n -> if n == 0 then 1 else n * fact (n - 1)
-- NO!
#+end_src

那么，考虑要解决的问题：在这种情况下，如何实现递归呢？一个很直观的思路是：由于函
数体中事实上只能访问传入的参数，那么，我们可以把函数自己传递给自己：
#+begin_src haskell
metafact = \ fact n -> if n == 0 then 1 else n * fact (n - 1)
#+end_src

那么，如何调用这个函数呢？
#+begin_src haskell
metafact (???) 3
#+end_src

先做一个简单的尝试，我们把 =metafact= 作为参数：
#+begin_src haskell
metafact (metafact (???)) 3
#+end_src

然而，作为参数传入的 =metafact= 也需要有一个能作为“自己”的参数才可以。由于不知道
是什么，我们先用 =undefined= 代替，进行计算：
#+begin_src haskell
metafact (metafact undefined) 3
=> if 3 == 0 then 1 else 3 * metafact undefined (3 - 1)
=> 3 * metafact undefined 2
=> 3 * if 2 == 0 then 1 else 2 * undefined (2 - 1)
=> 3 * 2 * undefined 1 -- Error!
#+end_src

显然，这样是行不通的，但事实上我们已经生成了一部分有用的表达式：$3 \times 2
\times \cdots$。注意到我们可以得到表达式的前两项，我们可以选取一个小一点的值来计
算：
#+begin_src haskell
metafact (metafact undefined) 1
=> if 1 == 0 then 1 else 1 * metafact undefined (1 - 1)
=> 1 * metafact undefined 0
=> 1 * if 0 == 0 then 1 else 0 * undefined (0 - 1)
=> 1 * 1 => 1 -- Okay
#+end_src

那么，我们也许找到了一条路：我们可以把 =metafact= 嵌套更多层数，这样，就能计算出
更长的表达式：
#+begin_src haskell
metafact (metafact (metafact (metafact ...))) n
#+end_src

事实上，对于嵌套了$n$层的 =metafact= 函数，就能够正确计算最大值为$n-1$的阶乘。例
如，对于嵌套了$1$层的 =metafact= ，仅可计算$n=0$的情况：
#+begin_src haskell
metafact undefined 0
=> if 0 == 0 then 1 else 0 * undefined (0 - 1)
=> 1 -- Okay
#+end_src

那么，自然地，为了得到一个可用的阶乘函数，我们只需要把 =metafact= 嵌套 /无限层/
即可！

无限——多么熟悉。Laziness是与无限打交道的最好方式之一。到了揭晓谜底的时候，考虑下
面的这个函数：$Y = \lambda f. (\lambda x. f \  (x \  x)) (\lambda x. f \  (x \
x))$。

这个函数有何特殊的呢？进行简单的计算化简：

$Y f = (\lambda x. f \ (x \ x)) (\lambda x. f \ (x \ x))$

$Y f = f \ ((\lambda x. f \ (x \ x)) (\lambda x. f \ (x \ x)))$

注意到，这意味着：$Y \ f = f \ (Y \  f)$。

这有什么作用呢？为了看的更清楚：
#+begin_src haskell
Y metafact
=> metafact (Y metafact)
=> metafact (metafact (Y metafact))
...
=> metafact (metafact ... (Y metafact) ... )
#+end_src

于是，我们得到了一个能够嵌套 /无限层/ 的函数，也即我们想要的 =fact= 函数——它能够
正确计算所有正整数的阶乘。

举一个具体的例子：
#+begin_src haskell
  (Y metafact) 3
  => metafact (Y metafact) 3
  => if 3 == 0 then 1 else 3 * (Y metafact) (3 - 1)
  => 3 * (Y metafact 2)
  => 3 * (metafact (Y metafact) 2)
  => 3 * if 2 == 0 then 1 else 2 * (Y metafact) (2 - 1)
  => 3 * 2 * (Y metafact 1)
  => 3 * 2 * metafact (Y metafact) 1
  => 3 * 2 * if 1 == 0 then 1 else 1 * (Y metafact) (1 - 1)
  => 3 * 2 * 1 * (Y metafact 0)
  => 3 * 2 * 1 * if 0 == 0 then 1 else 0 * (Y metafact) (0 - 1)
  => 3 * 2 * 1 * 1 => 6
#+end_src

至此，答案已然找到。$Y$这一函数，如同一根神奇的魔术棒，能够让一个任何一个函数进
行 /无限层/ 的嵌套。而归功于Laziness的性质，这种嵌套只会在需要时才会 /展开/ ，因
而不会产生死循环，也不会消耗无穷的内存，而是可以达到我们想要的效果。而利用$Y$函
数的这一特征，我们得以在无法引用自身的情况下，实现函数的递归。

需要注意的是，由于类型系统的限制，将$Y$函数翻译到Haskell中需要小小的作弊：
#+begin_src haskell
y :: forall a. (a -> a) -> a
y f = f (y f)
#+end_src

可以相信，这样定义的 =y= 和之前的$Y$是完全等价的。然而为了绕过类型系统的限制，我
们采用了化简之后的形式，并且不可避免地还是用到了递归，或者说，自引用 /(self
reference)/ 。

借助这一函数，我们可以容易地实现一些递归函数：
#+begin_src haskell
metamap :: ((a -> b) -> [a] -> [b]) -> (a -> b) -> [a] -> [b]
metamap = \ map f l ->
  match xs with
  | [] => []
  | x :: xs => f x : map f xs
  end
#+end_src

#+BEGIN_QUOTE
这里的 =match ... with ... end= 语法并非Haskell中的语法，而是从Coq中借鉴而来。
#+END_QUOTE

事实上，$Y$函数常常会被称为 Y Combinator，或是 Fixpoint Combinator。Fixpoint，也
即不动点，为何它会与不动点有关呢？考虑之前定义的 =metafact= 函数：
#+begin_src haskell
metafact = \ fact n -> if n == 0 then 1 else n * fact (n - 1)
#+end_src

有一个显而易见的事实：
#+begin_src haskell
metafact fact = fact
#+end_src

也即，如果将 =metafact= 看作一个函数，这个函数接受一个函数，返回值也是一个函数，
确切来说， =metafact= 的类型为：
#+begin_src haskell
metafact :: (Int -> Int) -> (Int -> Int)
#+end_src

那么，我们想得到的 =fact :: Int -> Int= 函数，事实上为 =metafact= 的 /不动点/ 。

另一方面，注意到 $Y f = f (Y f)$，也即若令 $x = Y f$，则$x = f(x)$。 *$Y f$就是
$f$的不动点！*

所以，我们要得到的递归函数 =fact= 就是 =metafact= 的不动点，而$Y$组合子就可以得
到函数$f$的不动点，所以，$Y$组合子的作用也可以从不动点的角度来解释。这也是$Y$组
合子也被称为不动点组合子的原因。

乍一看，本篇博客的一些假设显得非常怪异，简单地过分，甚至毫无必要。实现递归对于编
程语言而言其实是一件很简单的事情，在汇编代码中，只需要压入不同的参数，再次跳转到
函数的起始地址，就能实现递归调用。

然而，事实上，上文定义的语言近似于无类型的Lambda演算 /(Untyped Lambda Calculus)/
，而它是大多数函数式编程语言的基础。在很多函数式语言的编译器中，代码会被首先编译
为类似于Lambda演算的中间语言 (在Haskell中，这种中间表达的名称为 *Core* ），随后
再编译为更为底层的表示。而很多函数式编程语言中对自引用，或者说递归的实现，背后的
基础也正是$Y$组合子。

至此，对于Laziness的介绍以及对其作用的阐释告一段落了。简单地总结，这两篇博客：
- 介绍了Laziness的含义
- 分析了例子1：Laziness操作无限数列上的作用
- 分析了例子2：Laziness, Y组合子, 递归函数之间的联系

* TODO 利用FRP实现内网穿透                                         :tutorial:
:PROPERTIES:
:EXPORT_FILE_NAME: frp-guide
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:
本篇博客会简单地介绍FRP的配置与使用。

* DONE Hindley-Milner Type Inference for STLC and Its Extensions :test:type_system:
CLOSED: [2021-03-11 Thu 16:01]
:PROPERTIES:
:EXPORT_FILE_NAME: hm-type-inference-for-stlc
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :showDate true
:END:

In this post, we will introduce the principles of Algorithm W and Algorithm U,
the basis of the type inference in Hindley-Milner type system.

Firstly, we describe a small calculus, the well-known Simply-Typed
Lambda Calculus /(STLC)/.

** Simply-Typed Lambda Calculus

#+BEGIN_SRC text
  t ::= 'true'
      | 'false'
      | numericLiteral
      | 'pred' t
      | 'succ' t
      | 'iszero' t
      | 'if' t 'then' t 'else' t
      | x
      | '\' x [ ':' T ] '.' t
      | t t
      | 'let' x [ ':' T ] '=' t 'in' t
      | '(' t ')'

  T ::= 'Bool'
      | 'Nat'
      | T '->' T
      | '(' T ')'
#+END_SRC

** Type Inference for Hindley-Milner Type System

The type inference algorithm can be seperated into two parts:
- Algorithm W, which traverses the AST and collect constraints about types and
  type variables.

- Algorithm U, which computes the unification of the constraints.

*** Algorithm W: Constraint Generation

The typing rules are listed below. They can both derive term types and collect
constraints.

#+BEGIN_SRC text
  Γ ⊢ true : Bool | {}                       (T-True)

  Γ ⊢ false : Bool | {}                      (T-False)

  Γ ⊢ 0 : Nat | {}                           (T-Zero)

  Γ ⊢ t : T | C    C' = C ∪ {T = Nat}
  -----------------------------------        (T-Pred)
      Γ ⊢ pred t : Nat | C'

  Γ ⊢ t : T | C    C' = C ∪ {T = Nat}
  -----------------------------------        (T-Succ)
      Γ ⊢ succ t : Nat | C'

  Γ ⊢ t : T | C    C' = C ∪ {T = Nat}
  -----------------------------------        (T-IsZero)
    Γ ⊢ iszero t : Bool | C'

  Γ ⊢ t1: T1 | C1    Γ ⊢ t2 : T2 | C2
            Γ ⊢ t3 : T3 | C3
    C = C1 ∪ C2 ∪ C3 ∪ {T1 = Bool, T2 = T3}
  -----------------------------------------  (T-If)
    Γ ⊢ if t1 then t2 else t3 : T2 | C

    x : T ∈ Γ
  --------------                             (T-Var)
  Γ ⊢ x : T | {}

    Γ, x : T1 ⊢ t : T2 | C
  -----------------------------              (T-AbsGiven)
  Γ ⊢ λx: T1. t : T1 -> T2 | C

  Γ, x : X ⊢ t : T2 | C
        X is fresh
  ------------------------                   (T-AbsInfer)
  Γ ⊢ λx. t : X -> T2 | C

  Γ ⊢ t1 : T1 | C1    Γ ⊢ t2 : T2 | C2
  X is fresh, C = C1 ∪ C2 ∪ {T1 = T2 -> X}
  ----------------------------------------   (T-App)
          Γ ⊢ t1 t2 : X | C
#+END_SRC

The rules T-True, T-False and T-Zero are simply rules for constants. The rules
T-Pred, T-Succ and T-IsZero deals with operators on =Nat=, and they enforce the
parameter type to be =Nat= by adding a constraint =T = Nat=.

The rule T-If types the If expression, by requiring that the condition is of
type =Bool= and the type of the two bodies are the same.

The rule var reads the type of variable =x= in the environment.

The rule T-AbsGiven deals with lambda expressions where ascription of the
parameter is given. The T-AbsInfer rule generate a new type variable for the
lambda parameter and type the lambda as in T-AbsGiven.

The T-App types lambda application. It asserts that =t1= is of type =T2 -> X= for
some fresh type variable =X=.

*** Algorithm U: Constraint Unification

The constraints in our case are simply equations. Algorithm U will unify these
equations by processing them one by one to produce a substitution. For each
equation =S = T=,

1. S equals to T. Do nothing.

2. S is a type variable.
   1. If S appears in T, produce an error, since this is an infinite recursive
      type.

   2. Otherwise, add a substitution =S -> T=.

3. If T is a variable, similar to the previous case.

4. If both S and T are type constructors, which means they are both function
   types in our simple calculus, i.e. =S1 -> S2 = T1 -> T2=. We unify S1 and T1,
   S2 and T2 recursively.

5. In other cases, it fails.

** Extensions
*** Let Polymorphism
To be precise, the previously introduced calculus and type system is not HM. The
real HM has another feature: let-polymorphism. To see what is let polymorphism
and why it is useful, see the following example.

#+BEGIN_SRC haskell
  let id = \x. x
      add1 = succ x
  in (id add1) (id 1)
#+END_SRC

Here, =id= is an identity function, which is very common. However, this code
snippet will not type-check. Let's inspect the type-checking progress in
details.

Firstly, we derive that =id : X -> X= where =X= is a type variable based on the
definition of =id=. And similarly, we have =add1 : Y -> Nat | Y = Nat= when
typing the definition of =add1=. When typing =(id add1)=, we further get the
constraint =X -> X = (Y -> Nat) -> T1=. And when we type =(id 1)=, we get the
constraint =X -> X = Nat -> T2=.

During the unification process, we will first know that =X = Y -> Nat= from the
constraint =X -> X = (Y -> Nat) -> T1=, then know that =X = Nat= from the
constraint =X -> X = Nat -> T2=. We will finally try to unify =Y -> Nat = Nat=,
which will produce an error.

This is caused by the limitation of our current type system. Consider the
function =id = \x. x=. It can work on any type of parameter =x=. It ideally
should have a type like =forall a. a -> a=. The =forall a.= here is a form of
first-order polymorphism, which is the missing part of our current type system.
The technique we will use here, called let polymorphism, is a ad-hoc approach to
fuse first-order polymorphism into our type system without changing it too much.
This is why we call it an 'extension'.

We first introduce the definition of *type scheme*. It can be represented as
=forall X. T=, where =X= is a type variable bound in type =T=. Practically, it
can be represented by
#+BEGIN_SRC haskell
  data TypeScheme =
    TypeScheme { tvars :: List[TypeVar]
               , tpe   :: Type
               }
#+END_SRC
Here =Type= is some working implementation for types in the system.

The second step is to introduce two new rules in the
type system.

Following is the new typing rule to be introduced.
#+BEGIN_SRC text
  Γ ⊢ t : T | C   X does not occur in C
  -------------------------------------       (T-GenVar)
        Γ ⊢ t : forall X. T | C
#+END_SRC

The rule T-GenVar will generalize a type by generalizing all unconstrained type
variables in the type.

For example, the definition =id = \x. x= of type =X -> X= do not have any
constrain on the type variable =X=. So it will be generalized to a type scheme
=forall X. X -> X=.

The second rule to be introduced is T-InstVar. It instantiated type
variables in a type scheme.
#+BEGIN_SRC text
  Γ ⊢ t : forall X. T | C   X1 is fresh
  --------------------------------------     (T-InstVar)
          Γ ⊢ t : T [X -> X1] | C
#+END_SRC

By leveraging these two new rules, we can type the above example correctly.
Firstly the =id= will be typed as =forall X. X -> X=. In the expression =(id
add1)=, we first instantiate the type of =id= to =X1 -> X1= and produce the
constraint =X1 -> X1 = (Y -> Nat) -> T1=. For expression =(id 1)=, we again
instantiate the type of =id= to =X2 -> X2=, and get the constraint
=X2 -> X2 = Nat -> T2=. The expression can then be type-checked.

*** Fixpoint Operator

By paying the cost of fully collapse the logic corresponding to our calculus, we
can introduce the fixpoint operator to support general recursion in our small
language. The operator is of type =fix : forall X. (X -> X) -> X=.

We may add one more typing rule to support the operator.
#+BEGIN_SRC text
  Γ ⊢ t : T | C     C' = C ∪ {T = X -> X}
  ---------------------------------------    (T-Fix)
           Γ ⊢ fix t : X | C'
#+END_SRC

As mentioned before, this is at the cost of collapsing the logic system
correspoding to our type system. In the system with fix operator and this rule
enabled, False can be proved. Actually, we can write =fix (\x. x)=, which will
be typed as =forall X. X=, which is anything, and it is actually nothing, or the
False. This is how this rule destroy our logic completely.

*** Mutually-recursive Definitions

Mutually-recursive definition can be implemented via =fix= operator without
adding any more power into the language. However, it definitely makes sense to
add some special structure into the language to support mutually-recursive
definition groups and invent a new rule for typing them.

Consider the =letrec= construct, which is common in many ML family languages.
#+BEGIN_SRC haskell
  letrec even = \n. if iszero n then True else not (odd (pred n))
          odd = \n. if iszero n then False else not (even (pred n))
  in even
#+END_SRC

We can add the following typing rule.
#+BEGIN_SRC text
  Γ, x1 : X1, ..., xn : Xn ⊢ t1 : T1 | C1
  Γ, x1 : X1, ..., xn : Xn ⊢ t2 : T2 | C2
   ...
  Γ, x1 : X1, ..., xn : Xn ⊢ tn : Tn | Cn
  Γ, x1 : X1, ..., xn : Xn ⊢ t : T | C
  C' = C ∪ C1 ∪ C2 ∪ ... ∪ Cn ∪ {X1 = T1, ..., Xn = Tn}
  X1, X2, ..., Xn are fresh
  ----------------------------------------------------- (T-LetRec)
      Γ ⊢ letrec x1 = t1 ... xn = tn in t : T | C'
#+END_SRC

To type the above example, we first assume that =even : X1= and =odd : X2=. When
we type =even= and =odd=, we can get the following judgements:

- odd : Nat -> T2 | T2 = Bool
- even : T1 -> Bool | T1 = Nat
- even : Nat -> T3 | T3 = Bool
- odd : T4 -> Bool | T4 = Nat
- X1 = T1 -> Bool
- X1 = Nat -> T3
- X2 = Nat -> T2
- X2 = T4 -> Bool

Via unification, we can derive that
- T2 = Bool
- T1 = Nat
- T3 = Bool
- T4 = Nat
- X1 = Nat -> Bool
- X2 = Nat -> Bool

Therefore, the =letrec= expression can be typed as =Nat -> Bool=.

Note that, to show that =letrec= and the newly introduced typing rule is just
some 'syntax sugars', we can express what have done only with =fix= and tuple types.

#+BEGIN_SRC haskell
  let metaEvenOdd = \(even, odd) ->
      ( \n -> if iszero n then True else not (odd (succ n))
      , \n -> if iszero n then False else not (even (succ n))
      )
  in fix metaEvenOdd
#+END_SRC

We can type that
=metaEvenOdd : (Nat -> Bool, Nat -> Bool) -> (Nat -> Bool, Nat -> Bool)=
and know that
=fix : (Nat -> Bool, Nat -> Bool)=,
which is the desired mutually-recursive functions.

*** Record Types

We can add record types into the system. Following is the additional constructs.
#+BEGIN_SRC text
  t ::= { d* }
      | t '.' x

  d ::= x [ ':' T ] '=' t

  T ::= { D* }

  D ::= x ':' T
#+END_SRC

And we add new typing rules into the type system.
#+BEGIN_SRC text
  Γ, x1 : X1, ..., xn : Xn ⊢ t1 : T1 | C1
  Γ, x1 : X1, ..., xn : Xn ⊢ t2 : T2 | C2
   ...
  Γ, x1 : X1, ..., xn : Xn ⊢ tn : Tn | Cn
  C' = C1 ∪ C2 ∪ ... ∪ Cn ∪ { X1 = T1, ..., Xn = Tn }
  X1, X2, ..., Xn are fresh
  --------------------------------------------------------------  (T-Rec)
  Γ ⊢ { x1 = t1, ..., xn = tn } : { x1 : T1, ..., xn : Tn } | C'

  Γ ⊢ t : T | C
  C' = C ∪ { T <: { x : X } }
  ---------------------------                                     (T-Select)
  Γ ⊢ t.x : X | C'
#+END_SRC

Note that the new subtyping relation is introduced in rule T-Select. =S <: T=
means that =S= is a subtype of =T=. We do not have to introduce subtyping into
our system currently. =T <: { x : X }= in the constraint simply means that the
type T is a record type and its member =x= is of type =T=.

We can slightly modify Algorithm U to support record types and the subtyping
relation in the constraint. When we encounter a constraint =T <: { x : X }=, we
simply record the constraint in the type variable. Then, when we are going to
substute a type variable into a concrete type, we check whether they are
compatible.

Consider an example.
#+BEGIN_SRC haskell
  let f = \p -> plus p.x p.y
  in f { x = 1, y = 1 }
#+END_SRC

When typing the function =f=, we derive that
=f : T0 { x : T1, y : T2 } -> Int | T1 = Nat, T2 = Nat=.
And we can type that
={ x = 1, y = 1 } : { x : Nat, y : Nat }=.
From =f { x = 1, y = 1}=, we get the constraint that
=T1 { x : T1, y : T2 } -> Int = { x : Nat, y : Nat } -> T3=.

During the unification, we will try to unify
=T0 { x : T1, y : T2 }= and ={ x : Nat, y : Nat }=, which will further try to
unify =T1= and =Nat=, =T2= and =Nat=.

Finally, =f= will be typed as ={ x : Nat, y : Nat } -> Nat=, as expected.

Actually, in the =let= form, for type variables that are only constrained by
subtyping relations, we can generalize them just as if they are not constrained,
given that we record the required subtyping constraints into the type scheme. In
this way, the =f= will be typed as
=forall X <: { x : Nat, y : Nat } -> Nat=,
This change will enable the function to handle inputs like ={ x = 1, y = 1, z =
true }=, which will fails the type-check without the generalization.
Such technique can be named as /let subtyping polymorphism/.


** References
FOS 2020: https://fos2020.github.io
